{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import linalg as LA\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_autoencoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(sparse_autoencoder, self).__init__()\n",
    "        input_size = 784\n",
    "        output_size = 784      \n",
    "        self.hidden = nn.Linear(input_size, 256)\n",
    "        self.out = nn.Linear(256, output_size)\n",
    "        self.batch_size = 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.sigmoid(self.hidden(x))\n",
    "        y_hat = self.out(h)\n",
    "        return y_hat, h\n",
    "    \n",
    "    def loss(self, x, y, beta=0.1, rho=0.05):\n",
    "        y_hat, h = self.forward(x)\n",
    "        rho_hat = torch.sum(h, dim=0) / self.batch_size\n",
    "        c = nn.MSELoss()\n",
    "        l = c(y_hat, y) + beta * torch.sum(rho * torch.log(rho / rho_hat) + (1-rho) * torch.log((1-rho) / (1-rho_hat)))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = sparse_autoencoder()\n",
    "optimizer = optim.Adam(ae.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "trans = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1001, grad_fn=<DivBackward0>)\n",
      "tensor(0.0934, grad_fn=<DivBackward0>)\n",
      "tensor(0.0904, grad_fn=<DivBackward0>)\n",
      "tensor(0.0928, grad_fn=<DivBackward0>)\n",
      "tensor(0.0914, grad_fn=<DivBackward0>)\n",
      "tensor(0.0864, grad_fn=<DivBackward0>)\n",
      "tensor(0.0902, grad_fn=<DivBackward0>)\n",
      "tensor(0.0822, grad_fn=<DivBackward0>)\n",
      "tensor(0.0843, grad_fn=<DivBackward0>)\n",
      "tensor(0.0867, grad_fn=<DivBackward0>)\n",
      "tensor(0.0807, grad_fn=<DivBackward0>)\n",
      "tensor(0.0799, grad_fn=<DivBackward0>)\n",
      "tensor(0.0771, grad_fn=<DivBackward0>)\n",
      "tensor(0.0781, grad_fn=<DivBackward0>)\n",
      "tensor(0.0745, grad_fn=<DivBackward0>)\n",
      "tensor(0.0757, grad_fn=<DivBackward0>)\n",
      "tensor(0.0715, grad_fn=<DivBackward0>)\n",
      "tensor(0.0703, grad_fn=<DivBackward0>)\n",
      "tensor(0.0727, grad_fn=<DivBackward0>)\n",
      "tensor(0.0673, grad_fn=<DivBackward0>)\n",
      "tensor(0.0674, grad_fn=<DivBackward0>)\n",
      "tensor(0.0690, grad_fn=<DivBackward0>)\n",
      "tensor(0.0695, grad_fn=<DivBackward0>)\n",
      "tensor(0.0688, grad_fn=<DivBackward0>)\n",
      "tensor(0.0640, grad_fn=<DivBackward0>)\n",
      "tensor(0.0630, grad_fn=<DivBackward0>)\n",
      "tensor(0.0634, grad_fn=<DivBackward0>)\n",
      "tensor(0.0654, grad_fn=<DivBackward0>)\n",
      "tensor(0.0609, grad_fn=<DivBackward0>)\n",
      "tensor(0.0589, grad_fn=<DivBackward0>)\n",
      "tensor(0.0624, grad_fn=<DivBackward0>)\n",
      "tensor(0.0613, grad_fn=<DivBackward0>)\n",
      "tensor(0.0598, grad_fn=<DivBackward0>)\n",
      "tensor(0.0582, grad_fn=<DivBackward0>)\n",
      "tensor(0.0574, grad_fn=<DivBackward0>)\n",
      "tensor(0.0584, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    cnt = 0\n",
    "    l = 0\n",
    "    for data in trainset:\n",
    "        data = data[0].squeeze()\n",
    "        x = torch.reshape(data, (batch_size, 784))\n",
    "        y = x.clone()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, h = ae(x)\n",
    "        loss = ae.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l += loss\n",
    "        cnt += 1\n",
    "        if cnt % 600 == 0:\n",
    "            cnt = 0\n",
    "            print(l / 600)\n",
    "            l = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cnt = 0\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "for test in testset:\n",
    "    data = test[0].squeeze()\n",
    "    x = torch.reshape(data, (batch_size, 784))\n",
    "    out = ae(x)[0].detach().numpy()\n",
    "    cnt += 1\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'org.png', data[i], cmap='gray')\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'recovered.png', out[i].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
