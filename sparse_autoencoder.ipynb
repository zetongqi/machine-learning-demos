{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import linalg as LA\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparse_autoencoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(sparse_autoencoder, self).__init__()\n",
    "        input_size = 784\n",
    "        output_size = 784      \n",
    "        self.hidden = nn.Linear(input_size, 256)\n",
    "        self.out = nn.Linear(256, output_size)\n",
    "        self.batch_size = 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.sigmoid(self.hidden(x))\n",
    "        y_hat = F.relu(self.out(h))\n",
    "        return y_hat, h\n",
    "    \n",
    "    def loss(self, x, y, beta=0.1, rho=0.05):\n",
    "        y_hat, h = self.forward(x)\n",
    "        rho_hat = torch.sum(h, dim=0) / self.batch_size\n",
    "        c = nn.MSELoss()\n",
    "        l = c(y_hat, y) + beta * torch.sum(rho * torch.log(rho / rho_hat) + (1-rho) * torch.log((1-rho) / (1-rho_hat)))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = sparse_autoencoder()\n",
    "optimizer = optim.Adam(ae.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "trans = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2088, grad_fn=<DivBackward0>)\n",
      "tensor(0.0998, grad_fn=<DivBackward0>)\n",
      "tensor(0.0880, grad_fn=<DivBackward0>)\n",
      "tensor(0.0791, grad_fn=<DivBackward0>)\n",
      "tensor(0.0713, grad_fn=<DivBackward0>)\n",
      "tensor(0.0655, grad_fn=<DivBackward0>)\n",
      "tensor(0.0608, grad_fn=<DivBackward0>)\n",
      "tensor(0.0568, grad_fn=<DivBackward0>)\n",
      "tensor(0.0532, grad_fn=<DivBackward0>)\n",
      "tensor(0.0497, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    cnt = 0\n",
    "    l = 0\n",
    "    for data in trainset:\n",
    "        data = data[0].squeeze()\n",
    "        x = torch.reshape(data, (batch_size, 784))\n",
    "        y = x.clone()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, h = ae(x)\n",
    "        loss = ae.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l += loss\n",
    "        cnt += 1\n",
    "        if cnt % 6000 == 0:\n",
    "            cnt = 0\n",
    "            print(l / 6000)\n",
    "            l = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cnt = 0\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "for test in testset:\n",
    "    data = test[0].squeeze()\n",
    "    x = torch.reshape(data, (batch_size, 784))\n",
    "    out = ae(x)[0].detach().numpy()\n",
    "    cnt += 1\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'org.png', data[i], cmap='gray')\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'recovered.png', out[i].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = list(ae.parameters())\n",
    "en = w[0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"latent\", exist_ok=True)\n",
    "cnt = 0\n",
    "for i in en:\n",
    "    cnt += 1\n",
    "    plt.imsave('./latent/' + str(cnt)+ 'latent.png', i.reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
