{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import linalg as LA\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussian_sample_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(gaussian_sample_layer, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.L = 1\n",
    "        \n",
    "    def forward(self, mu, sigma):\n",
    "        epsilon_dist = torch.distributions.MultivariateNormal(torch.zeros(self.latent_dim),torch.eye(self.latent_dim))\n",
    "        epsilon = epsilon_dist.sample((self.L,))\n",
    "        epsilon = torch.sum(epsilon, dim=0) / self.L\n",
    "        a = mu + epsilon * sigma\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class variational_autoencoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(variational_autoencoder, self).__init__()\n",
    "        input_size = 784\n",
    "        output_size = 784\n",
    "        self.latent_dim = 2\n",
    "        self.mlp1 = nn.Linear(input_size, 128)\n",
    "        self.mu = nn.Linear(128, self.latent_dim)\n",
    "        self.sigma = nn.Linear(128, self.latent_dim)\n",
    "        self.gaussian = gaussian_sample_layer(self.latent_dim)\n",
    "        self.mlp4 = nn.Linear(self.latent_dim, 128)\n",
    "        self.out = nn.Linear(128, output_size)\n",
    "        self.batch_size = 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.sigmoid(self.mlp1(x))\n",
    "        mu = F.sigmoid(self.mu(h1))\n",
    "        sigma = F.sigmoid(self.sigma(h1))\n",
    "        z = self.gaussian(mu, sigma)\n",
    "        h4 = F.tanh(self.mlp4(z))\n",
    "        y_hat = F.relu(self.out(h4))\n",
    "        return y_hat, mu, sigma\n",
    "    \n",
    "    def loss(self, x, y, beta=0.0001):\n",
    "        y_hat, mu, sigma = self.forward(x)\n",
    "        c = nn.MSELoss()\n",
    "        l = c(y_hat, y) - beta * 1/2 * torch.sum(1 + torch.log(sigma**2) - mu**2 - sigma**2)\n",
    "        return l\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        f = F.relu(self.out(F.tanh(self.mlp4(x))))\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = variational_autoencoder()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(544.1953, grad_fn=<AddBackward0>)\n",
      "tensor(523.0386, grad_fn=<AddBackward0>)\n",
      "tensor(513.8260, grad_fn=<AddBackward0>)\n",
      "tensor(502.2106, grad_fn=<AddBackward0>)\n",
      "tensor(490.5596, grad_fn=<AddBackward0>)\n",
      "tensor(484.1887, grad_fn=<AddBackward0>)\n",
      "tensor(479.0475, grad_fn=<AddBackward0>)\n",
      "tensor(474.9055, grad_fn=<AddBackward0>)\n",
      "tensor(470.0655, grad_fn=<AddBackward0>)\n",
      "tensor(465.0965, grad_fn=<AddBackward0>)\n",
      "tensor(459.9419, grad_fn=<AddBackward0>)\n",
      "tensor(456.2365, grad_fn=<AddBackward0>)\n",
      "tensor(450.8407, grad_fn=<AddBackward0>)\n",
      "tensor(448.2797, grad_fn=<AddBackward0>)\n",
      "tensor(446.8343, grad_fn=<AddBackward0>)\n",
      "tensor(442.5983, grad_fn=<AddBackward0>)\n",
      "tensor(438.1119, grad_fn=<AddBackward0>)\n",
      "tensor(436.9942, grad_fn=<AddBackward0>)\n",
      "tensor(435.7184, grad_fn=<AddBackward0>)\n",
      "tensor(434.1134, grad_fn=<AddBackward0>)\n",
      "tensor(432.0978, grad_fn=<AddBackward0>)\n",
      "tensor(431.2682, grad_fn=<AddBackward0>)\n",
      "tensor(430.0606, grad_fn=<AddBackward0>)\n",
      "tensor(428.2201, grad_fn=<AddBackward0>)\n",
      "tensor(425.8666, grad_fn=<AddBackward0>)\n",
      "tensor(421.6270, grad_fn=<AddBackward0>)\n",
      "tensor(420.6736, grad_fn=<AddBackward0>)\n",
      "tensor(418.0339, grad_fn=<AddBackward0>)\n",
      "tensor(416.4806, grad_fn=<AddBackward0>)\n",
      "tensor(415.8923, grad_fn=<AddBackward0>)\n",
      "tensor(412.7209, grad_fn=<AddBackward0>)\n",
      "tensor(411.9429, grad_fn=<AddBackward0>)\n",
      "tensor(411.3037, grad_fn=<AddBackward0>)\n",
      "tensor(410.4754, grad_fn=<AddBackward0>)\n",
      "tensor(409.8755, grad_fn=<AddBackward0>)\n",
      "tensor(408.9599, grad_fn=<AddBackward0>)\n",
      "tensor(406.7461, grad_fn=<AddBackward0>)\n",
      "tensor(406.3194, grad_fn=<AddBackward0>)\n",
      "tensor(405.5793, grad_fn=<AddBackward0>)\n",
      "tensor(405.0522, grad_fn=<AddBackward0>)\n",
      "tensor(404.4956, grad_fn=<AddBackward0>)\n",
      "tensor(401.3759, grad_fn=<AddBackward0>)\n",
      "tensor(400.7508, grad_fn=<AddBackward0>)\n",
      "tensor(400.2054, grad_fn=<AddBackward0>)\n",
      "tensor(399.5938, grad_fn=<AddBackward0>)\n",
      "tensor(399.1831, grad_fn=<AddBackward0>)\n",
      "tensor(398.6289, grad_fn=<AddBackward0>)\n",
      "tensor(398.1858, grad_fn=<AddBackward0>)\n",
      "tensor(397.8532, grad_fn=<AddBackward0>)\n",
      "tensor(397.4475, grad_fn=<AddBackward0>)\n",
      "tensor(396.9714, grad_fn=<AddBackward0>)\n",
      "tensor(395.9655, grad_fn=<AddBackward0>)\n",
      "tensor(392.9136, grad_fn=<AddBackward0>)\n",
      "tensor(391.9680, grad_fn=<AddBackward0>)\n",
      "tensor(391.4635, grad_fn=<AddBackward0>)\n",
      "tensor(391.1796, grad_fn=<AddBackward0>)\n",
      "tensor(390.5501, grad_fn=<AddBackward0>)\n",
      "tensor(390.1248, grad_fn=<AddBackward0>)\n",
      "tensor(389.9605, grad_fn=<AddBackward0>)\n",
      "tensor(389.5768, grad_fn=<AddBackward0>)\n",
      "tensor(389.3583, grad_fn=<AddBackward0>)\n",
      "tensor(389.0301, grad_fn=<AddBackward0>)\n",
      "tensor(388.9474, grad_fn=<AddBackward0>)\n",
      "tensor(388.5680, grad_fn=<AddBackward0>)\n",
      "tensor(388.2805, grad_fn=<AddBackward0>)\n",
      "tensor(388.0569, grad_fn=<AddBackward0>)\n",
      "tensor(387.8445, grad_fn=<AddBackward0>)\n",
      "tensor(387.6888, grad_fn=<AddBackward0>)\n",
      "tensor(387.4612, grad_fn=<AddBackward0>)\n",
      "tensor(387.3686, grad_fn=<AddBackward0>)\n",
      "tensor(387.1213, grad_fn=<AddBackward0>)\n",
      "tensor(386.8357, grad_fn=<AddBackward0>)\n",
      "tensor(386.7669, grad_fn=<AddBackward0>)\n",
      "tensor(386.5309, grad_fn=<AddBackward0>)\n",
      "tensor(386.1944, grad_fn=<AddBackward0>)\n",
      "tensor(386.1991, grad_fn=<AddBackward0>)\n",
      "tensor(385.8311, grad_fn=<AddBackward0>)\n",
      "tensor(385.6109, grad_fn=<AddBackward0>)\n",
      "tensor(385.1525, grad_fn=<AddBackward0>)\n",
      "tensor(385.0456, grad_fn=<AddBackward0>)\n",
      "tensor(384.8771, grad_fn=<AddBackward0>)\n",
      "tensor(384.6620, grad_fn=<AddBackward0>)\n",
      "tensor(384.5997, grad_fn=<AddBackward0>)\n",
      "tensor(384.3316, grad_fn=<AddBackward0>)\n",
      "tensor(384.3192, grad_fn=<AddBackward0>)\n",
      "tensor(384.0089, grad_fn=<AddBackward0>)\n",
      "tensor(383.8938, grad_fn=<AddBackward0>)\n",
      "tensor(383.5387, grad_fn=<AddBackward0>)\n",
      "tensor(383.5503, grad_fn=<AddBackward0>)\n",
      "tensor(383.4495, grad_fn=<AddBackward0>)\n",
      "tensor(382.9952, grad_fn=<AddBackward0>)\n",
      "tensor(383.0713, grad_fn=<AddBackward0>)\n",
      "tensor(382.9632, grad_fn=<AddBackward0>)\n",
      "tensor(382.7968, grad_fn=<AddBackward0>)\n",
      "tensor(382.5040, grad_fn=<AddBackward0>)\n",
      "tensor(382.4315, grad_fn=<AddBackward0>)\n",
      "tensor(382.1681, grad_fn=<AddBackward0>)\n",
      "tensor(382.1957, grad_fn=<AddBackward0>)\n",
      "tensor(381.8468, grad_fn=<AddBackward0>)\n",
      "tensor(381.6166, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    cnt = 0\n",
    "    l = 0\n",
    "    for data in trainset:\n",
    "        data = data[0].squeeze()\n",
    "        x = torch.reshape(data, (batch_size, 784))\n",
    "        y = x.clone()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, _, _ = vae(x)\n",
    "        loss = vae.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l += loss\n",
    "        cnt += 1\n",
    "    print(l)\n",
    "    '''if cnt % 600 == 0:\n",
    "            cnt = 0\n",
    "            print(l / 600)\n",
    "            l = 0'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cnt = 0\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "for test in testset:\n",
    "    data = test[0].squeeze()\n",
    "    x = torch.reshape(data, (batch_size, 784))\n",
    "    out = vae(x)[0].detach().numpy()\n",
    "    cnt += 1\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'org.png', data[i], cmap='gray')\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'recovered.png', out[i].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for w in vae.parameters():\n",
    "    weights.append(w)\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "for i in range(1000):\n",
    "    dist = torch.distributions.MultivariateNormal(torch.zeros(2),torch.eye(2))\n",
    "    z = dist.sample()\n",
    "    plt.imsave('./generated/' + str(i)+'.png', vae.decoder(z).detach().numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "x = np.linspace(0, 1, num=steps)\n",
    "y = np.linspace(0, 1, num=steps)\n",
    "z = []\n",
    "for xval in x:\n",
    "    for yval in y:\n",
    "        z.append((xval, yval))\n",
    "z = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"grid\", exist_ok=True)\n",
    "cnt = 0\n",
    "for pair in z:\n",
    "    cnt += 1\n",
    "    plt.imsave('./grid/' + str(cnt)+'.png', vae.decoder(torch.from_numpy(pair).float()).detach().numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
