{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import linalg as LA\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gaussian_sample_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(gaussian_sample_layer, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.L = 1\n",
    "        \n",
    "    def forward(self, mu, sigma):\n",
    "        epsilon_dist = torch.distributions.MultivariateNormal(torch.zeros(self.latent_dim),torch.eye(self.latent_dim))\n",
    "        epsilon = epsilon_dist.sample((self.L,))\n",
    "        epsilon = torch.sum(epsilon, dim=0) / self.L\n",
    "        a = mu + epsilon * sigma\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class variational_autoencoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(variational_autoencoder, self).__init__()\n",
    "        input_size = 784\n",
    "        output_size = 784\n",
    "        self.latent_dim = 16\n",
    "        self.mlp1 = nn.Linear(input_size, 128)\n",
    "        self.mu = nn.Linear(128, self.latent_dim)\n",
    "        self.sigma = nn.Linear(128, self.latent_dim)\n",
    "        self.gaussian = gaussian_sample_layer(self.latent_dim)\n",
    "        self.mlp4 = nn.Linear(self.latent_dim, 128)\n",
    "        self.out = nn.Linear(128, output_size)\n",
    "        self.batch_size = 8\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.sigmoid(self.mlp1(x))\n",
    "        mu = F.sigmoid(self.mu(h1))\n",
    "        sigma = F.sigmoid(self.sigma(h1))\n",
    "        z = self.gaussian(mu, sigma)\n",
    "        h4 = F.tanh(self.mlp4(z))\n",
    "        y_hat = F.relu(self.out(h4))\n",
    "        return y_hat, mu, sigma\n",
    "    \n",
    "    def loss(self, x, y, beta=0.0001):\n",
    "        y_hat, mu, sigma = self.forward(x)\n",
    "        c = nn.MSELoss()\n",
    "        l = c(y_hat, y) - beta * 1/2 * torch.sum(1 + torch.log(sigma**2) - mu**2 - sigma**2)\n",
    "        return l\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        f = F.relu(self.out(F.tanh(self.mlp4(x))))\n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = variational_autoencoder()\n",
    "optimizer = optim.Adam(vae.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(473.1535, grad_fn=<AddBackward0>)\n",
      "tensor(416.5661, grad_fn=<AddBackward0>)\n",
      "tensor(402.3413, grad_fn=<AddBackward0>)\n",
      "tensor(395.5591, grad_fn=<AddBackward0>)\n",
      "tensor(388.6825, grad_fn=<AddBackward0>)\n",
      "tensor(382.5290, grad_fn=<AddBackward0>)\n",
      "tensor(376.9836, grad_fn=<AddBackward0>)\n",
      "tensor(371.5956, grad_fn=<AddBackward0>)\n",
      "tensor(366.5996, grad_fn=<AddBackward0>)\n",
      "tensor(362.1712, grad_fn=<AddBackward0>)\n",
      "tensor(358.1848, grad_fn=<AddBackward0>)\n",
      "tensor(355.2062, grad_fn=<AddBackward0>)\n",
      "tensor(352.0761, grad_fn=<AddBackward0>)\n",
      "tensor(349.6087, grad_fn=<AddBackward0>)\n",
      "tensor(347.6811, grad_fn=<AddBackward0>)\n",
      "tensor(345.6353, grad_fn=<AddBackward0>)\n",
      "tensor(344.0138, grad_fn=<AddBackward0>)\n",
      "tensor(342.5093, grad_fn=<AddBackward0>)\n",
      "tensor(340.7488, grad_fn=<AddBackward0>)\n",
      "tensor(339.8383, grad_fn=<AddBackward0>)\n",
      "tensor(338.6263, grad_fn=<AddBackward0>)\n",
      "tensor(337.5218, grad_fn=<AddBackward0>)\n",
      "tensor(336.7500, grad_fn=<AddBackward0>)\n",
      "tensor(335.5693, grad_fn=<AddBackward0>)\n",
      "tensor(334.8258, grad_fn=<AddBackward0>)\n",
      "tensor(333.9747, grad_fn=<AddBackward0>)\n",
      "tensor(333.1099, grad_fn=<AddBackward0>)\n",
      "tensor(332.1026, grad_fn=<AddBackward0>)\n",
      "tensor(331.6406, grad_fn=<AddBackward0>)\n",
      "tensor(331.0723, grad_fn=<AddBackward0>)\n",
      "tensor(329.9713, grad_fn=<AddBackward0>)\n",
      "tensor(329.6624, grad_fn=<AddBackward0>)\n",
      "tensor(328.8700, grad_fn=<AddBackward0>)\n",
      "tensor(328.1242, grad_fn=<AddBackward0>)\n",
      "tensor(328.4136, grad_fn=<AddBackward0>)\n",
      "tensor(327.6898, grad_fn=<AddBackward0>)\n",
      "tensor(326.8683, grad_fn=<AddBackward0>)\n",
      "tensor(326.4529, grad_fn=<AddBackward0>)\n",
      "tensor(326.1416, grad_fn=<AddBackward0>)\n",
      "tensor(325.8566, grad_fn=<AddBackward0>)\n",
      "tensor(325.1493, grad_fn=<AddBackward0>)\n",
      "tensor(324.3466, grad_fn=<AddBackward0>)\n",
      "tensor(324.1962, grad_fn=<AddBackward0>)\n",
      "tensor(323.7747, grad_fn=<AddBackward0>)\n",
      "tensor(323.6209, grad_fn=<AddBackward0>)\n",
      "tensor(322.7852, grad_fn=<AddBackward0>)\n",
      "tensor(322.5945, grad_fn=<AddBackward0>)\n",
      "tensor(322.2821, grad_fn=<AddBackward0>)\n",
      "tensor(321.7671, grad_fn=<AddBackward0>)\n",
      "tensor(321.6111, grad_fn=<AddBackward0>)\n",
      "tensor(321.3909, grad_fn=<AddBackward0>)\n",
      "tensor(321.0695, grad_fn=<AddBackward0>)\n",
      "tensor(320.6505, grad_fn=<AddBackward0>)\n",
      "tensor(320.0619, grad_fn=<AddBackward0>)\n",
      "tensor(319.5958, grad_fn=<AddBackward0>)\n",
      "tensor(319.5569, grad_fn=<AddBackward0>)\n",
      "tensor(319.2727, grad_fn=<AddBackward0>)\n",
      "tensor(319.2830, grad_fn=<AddBackward0>)\n",
      "tensor(318.7625, grad_fn=<AddBackward0>)\n",
      "tensor(318.6631, grad_fn=<AddBackward0>)\n",
      "tensor(318.4126, grad_fn=<AddBackward0>)\n",
      "tensor(318.1256, grad_fn=<AddBackward0>)\n",
      "tensor(317.4857, grad_fn=<AddBackward0>)\n",
      "tensor(317.6925, grad_fn=<AddBackward0>)\n",
      "tensor(317.4725, grad_fn=<AddBackward0>)\n",
      "tensor(316.9333, grad_fn=<AddBackward0>)\n",
      "tensor(316.4060, grad_fn=<AddBackward0>)\n",
      "tensor(316.3946, grad_fn=<AddBackward0>)\n",
      "tensor(316.2174, grad_fn=<AddBackward0>)\n",
      "tensor(315.7975, grad_fn=<AddBackward0>)\n",
      "tensor(315.3632, grad_fn=<AddBackward0>)\n",
      "tensor(315.1122, grad_fn=<AddBackward0>)\n",
      "tensor(314.9603, grad_fn=<AddBackward0>)\n",
      "tensor(314.7814, grad_fn=<AddBackward0>)\n",
      "tensor(314.6049, grad_fn=<AddBackward0>)\n",
      "tensor(314.2373, grad_fn=<AddBackward0>)\n",
      "tensor(314.1437, grad_fn=<AddBackward0>)\n",
      "tensor(313.8299, grad_fn=<AddBackward0>)\n",
      "tensor(313.6850, grad_fn=<AddBackward0>)\n",
      "tensor(313.1410, grad_fn=<AddBackward0>)\n",
      "tensor(313.3203, grad_fn=<AddBackward0>)\n",
      "tensor(313.3709, grad_fn=<AddBackward0>)\n",
      "tensor(313.0712, grad_fn=<AddBackward0>)\n",
      "tensor(312.9266, grad_fn=<AddBackward0>)\n",
      "tensor(312.4560, grad_fn=<AddBackward0>)\n",
      "tensor(312.8789, grad_fn=<AddBackward0>)\n",
      "tensor(312.5828, grad_fn=<AddBackward0>)\n",
      "tensor(312.5216, grad_fn=<AddBackward0>)\n",
      "tensor(312.0110, grad_fn=<AddBackward0>)\n",
      "tensor(311.8506, grad_fn=<AddBackward0>)\n",
      "tensor(311.9903, grad_fn=<AddBackward0>)\n",
      "tensor(311.5747, grad_fn=<AddBackward0>)\n",
      "tensor(311.5619, grad_fn=<AddBackward0>)\n",
      "tensor(311.4389, grad_fn=<AddBackward0>)\n",
      "tensor(310.9764, grad_fn=<AddBackward0>)\n",
      "tensor(311.2124, grad_fn=<AddBackward0>)\n",
      "tensor(311.0140, grad_fn=<AddBackward0>)\n",
      "tensor(310.8496, grad_fn=<AddBackward0>)\n",
      "tensor(310.5838, grad_fn=<AddBackward0>)\n",
      "tensor(310.8170, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    cnt = 0\n",
    "    l = 0\n",
    "    for data in trainset:\n",
    "        data = data[0].squeeze()\n",
    "        x = torch.reshape(data, (batch_size, 784))\n",
    "        y = x.clone()\n",
    "        optimizer.zero_grad()\n",
    "        y_hat, _, _ = vae(x)\n",
    "        loss = vae.loss(x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l += loss\n",
    "        cnt += 1\n",
    "    print(l)\n",
    "    '''if cnt % 600 == 0:\n",
    "            cnt = 0\n",
    "            print(l / 600)\n",
    "            l = 0'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "cnt = 0\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "for test in testset:\n",
    "    data = test[0].squeeze()\n",
    "    x = torch.reshape(data, (batch_size, 784))\n",
    "    out = vae(x)[0].detach().numpy()\n",
    "    cnt += 1\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'org.png', data[i], cmap='gray')\n",
    "        plt.imsave('./img/' + str(cnt) + str(i) + 'recovered.png', out[i].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for w in vae.parameters():\n",
    "    weights.append(w)\n",
    "weights = np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "for i in range(1000):\n",
    "    dist = torch.distributions.MultivariateNormal(torch.zeros(16),torch.eye(16))\n",
    "    z = dist.sample()\n",
    "    plt.imsave('./generated/' + str(i)+'.png', vae.decoder(z).detach().numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
