{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAL-9000 intent classification demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from pymagnitude import *\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load intents dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "with open(\"/Users/zetong/intents.csv\", mode = 'r', encoding = 'ascii', errors = 'ignore') as csvfile:\n",
    "    intents = pd.read_csv(csvfile)\n",
    "    X = list(intents[\"utterances\"])\n",
    "    y = list(intents[\"labels\"])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Magnitude(\"/Users/zetong/Downloads/glove.840B.300d.magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 18:24:01.781563 4599846336 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:24:01.790469 4599846336 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:24:01.791351 4599846336 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:24:01.792001 4599846336 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 300)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 28, 64)            85248     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                693       \n",
      "=================================================================\n",
      "Total params: 88,021\n",
      "Trainable params: 88,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 28\n",
    "i = tf.keras.layers.Input(shape=(MAX_SEQ_LEN, vectors.dim))\n",
    "Bidir_LSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, activation=\"tanh\", return_sequences=True),merge_mode=\"concat\",)(i)\n",
    "maxpool = tf.keras.layers.GlobalMaxPooling1D()(Bidir_LSTM)\n",
    "hidden = tf.keras.layers.Dense(32)(maxpool)\n",
    "dropout = tf.keras.layers.Dropout(0.3)(hidden)\n",
    "output = tf.keras.layers.Dense(le.classes_.shape[0], activation=\"softmax\")(dropout)\n",
    "model = tf.keras.Model(inputs=i, outputs=output)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(xarr, yarr):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((xarr, yarr)).repeat()\n",
    "    \n",
    "    def _process_string(x):\n",
    "\n",
    "        # x is numpy array\n",
    "        def _pad_zeros(x, MAX_SEQ_LEN):\n",
    "            if x.shape[0] >= MAX_SEQ_LEN:\n",
    "                return x[0:MAX_SEQ_LEN, :]\n",
    "            else:\n",
    "                return np.concatenate(\n",
    "                    (x, np.zeros((MAX_SEQ_LEN - x.shape[0], x.shape[1]))), axis=0\n",
    "                )\n",
    "        stemmer = LancasterStemmer()\n",
    "        x = x.numpy().decode()\n",
    "        x = word_tokenize(x)\n",
    "        x = [stemmer.stem(i) for i in x]\n",
    "        if len(x) != 0:\n",
    "            x = vectors.query(x)\n",
    "            x = _pad_zeros(x, MAX_SEQ_LEN)\n",
    "        else:\n",
    "            x = np.zeros((MAX_SEQ_LEN, vectors.dim))\n",
    "        return x\n",
    "    \n",
    "    def _process_datapair(X, y):\n",
    "        X = tf.py_function(_process_string, [X], tf.float32)\n",
    "        X.set_shape([MAX_SEQ_LEN, vectors.dim])\n",
    "        y.set_shape([])\n",
    "        return X, y\n",
    "    \n",
    "    dataset = dataset.map(_process_datapair)\n",
    "    return dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train = make_dataset(X_train, y_train)\n",
    "val = make_dataset(X_val, y_val)\n",
    "test = make_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 18:24:02.745737 4599846336 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 18:24:04.946165 123145552084992 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:24:04.970221 123145553158144 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:24:04.983597 123145553158144 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:24:04.988615 123145553158144 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:24:04.995657 123145552084992 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/25 [===============================] - 8s 324ms/step - loss: 2.9353 - acc: 0.1635 - val_loss: 3.0409 - val_acc: 0.0729\n",
      "Epoch 2/100\n",
      "26/25 [===============================] - 2s 72ms/step - loss: 2.6708 - acc: 0.1875 - val_loss: 2.9059 - val_acc: 0.0938\n",
      "Epoch 3/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 2.4907 - acc: 0.2043 - val_loss: 2.6970 - val_acc: 0.1562\n",
      "Epoch 4/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 2.2494 - acc: 0.3450 - val_loss: 2.2740 - val_acc: 0.5104\n",
      "Epoch 5/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 1.9195 - acc: 0.4555 - val_loss: 1.8577 - val_acc: 0.5729\n",
      "Epoch 6/100\n",
      "26/25 [===============================] - 2s 71ms/step - loss: 1.5780 - acc: 0.5925 - val_loss: 1.7173 - val_acc: 0.5521\n",
      "Epoch 7/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 1.2559 - acc: 0.6526 - val_loss: 1.3780 - val_acc: 0.6458\n",
      "Epoch 8/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 1.0985 - acc: 0.7248 - val_loss: 1.0246 - val_acc: 0.7500\n",
      "Epoch 9/100\n",
      "26/25 [===============================] - 2s 69ms/step - loss: 0.9120 - acc: 0.7849 - val_loss: 1.1137 - val_acc: 0.8021\n",
      "Epoch 10/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.7483 - acc: 0.8257 - val_loss: 0.8803 - val_acc: 0.7708\n",
      "Epoch 11/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.6547 - acc: 0.8486 - val_loss: 0.7397 - val_acc: 0.8125\n",
      "Epoch 12/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.6225 - acc: 0.8413 - val_loss: 0.7134 - val_acc: 0.7917\n",
      "Epoch 13/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.6056 - acc: 0.8582 - val_loss: 0.8848 - val_acc: 0.7917\n",
      "Epoch 14/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.5036 - acc: 0.8606 - val_loss: 0.6725 - val_acc: 0.8333\n",
      "Epoch 15/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.4744 - acc: 0.8822 - val_loss: 0.8723 - val_acc: 0.7812\n",
      "Epoch 16/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.5296 - acc: 0.8642 - val_loss: 0.6930 - val_acc: 0.8750\n",
      "Epoch 17/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.4179 - acc: 0.8954 - val_loss: 0.3932 - val_acc: 0.9271\n",
      "Epoch 18/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.3493 - acc: 0.9111 - val_loss: 0.6905 - val_acc: 0.8333\n",
      "Epoch 19/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.3436 - acc: 0.9147 - val_loss: 0.7289 - val_acc: 0.8229\n",
      "Epoch 20/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.3279 - acc: 0.9147 - val_loss: 0.4961 - val_acc: 0.8646\n",
      "Epoch 21/100\n",
      "26/25 [===============================] - 2s 69ms/step - loss: 0.3563 - acc: 0.9062 - val_loss: 0.7675 - val_acc: 0.8229\n",
      "Epoch 22/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.3686 - acc: 0.9062 - val_loss: 0.6914 - val_acc: 0.8021\n",
      "Epoch 23/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.2923 - acc: 0.9291 - val_loss: 0.4826 - val_acc: 0.8438\n",
      "Epoch 24/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.2665 - acc: 0.9351 - val_loss: 0.4238 - val_acc: 0.8750\n",
      "Epoch 25/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.2428 - acc: 0.9315 - val_loss: 0.6493 - val_acc: 0.8021\n",
      "Epoch 26/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.2124 - acc: 0.9447 - val_loss: 0.5681 - val_acc: 0.8125\n",
      "Epoch 27/100\n",
      "26/25 [===============================] - 2s 69ms/step - loss: 0.2358 - acc: 0.9315 - val_loss: 0.6705 - val_acc: 0.8125\n",
      "Epoch 28/100\n",
      "26/25 [===============================] - 2s 79ms/step - loss: 0.2361 - acc: 0.9375 - val_loss: 0.3438 - val_acc: 0.8854\n",
      "Epoch 29/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.2236 - acc: 0.9459 - val_loss: 0.4985 - val_acc: 0.8229\n",
      "Epoch 30/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1818 - acc: 0.9627 - val_loss: 0.4467 - val_acc: 0.8646\n",
      "Epoch 31/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1970 - acc: 0.9555 - val_loss: 0.6963 - val_acc: 0.7917\n",
      "Epoch 32/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.2401 - acc: 0.9351 - val_loss: 0.4932 - val_acc: 0.8438\n",
      "Epoch 33/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1678 - acc: 0.9531 - val_loss: 0.5860 - val_acc: 0.7708\n",
      "Epoch 34/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1612 - acc: 0.9651 - val_loss: 0.3841 - val_acc: 0.8438\n",
      "Epoch 35/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1519 - acc: 0.9603 - val_loss: 0.6237 - val_acc: 0.7917\n",
      "Epoch 36/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1461 - acc: 0.9639 - val_loss: 0.4624 - val_acc: 0.8125\n",
      "Epoch 37/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1470 - acc: 0.9651 - val_loss: 0.3535 - val_acc: 0.8750\n",
      "Epoch 38/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1583 - acc: 0.9567 - val_loss: 0.5248 - val_acc: 0.8229\n",
      "Epoch 39/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1331 - acc: 0.9651 - val_loss: 0.6009 - val_acc: 0.8438\n",
      "Epoch 40/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1057 - acc: 0.9784 - val_loss: 0.3780 - val_acc: 0.8750\n",
      "Epoch 41/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0946 - acc: 0.9832 - val_loss: 0.4887 - val_acc: 0.8333\n",
      "Epoch 42/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1232 - acc: 0.9651 - val_loss: 0.4370 - val_acc: 0.8438\n",
      "Epoch 43/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0902 - acc: 0.9832 - val_loss: 0.4232 - val_acc: 0.8542\n",
      "Epoch 44/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0843 - acc: 0.9868 - val_loss: 0.6092 - val_acc: 0.8333\n",
      "Epoch 45/100\n",
      "26/25 [===============================] - 2s 69ms/step - loss: 0.1005 - acc: 0.9748 - val_loss: 0.3333 - val_acc: 0.8854\n",
      "Epoch 46/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0923 - acc: 0.9784 - val_loss: 0.5100 - val_acc: 0.8750\n",
      "Epoch 47/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1145 - acc: 0.9700 - val_loss: 0.4681 - val_acc: 0.8542\n",
      "Epoch 48/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1049 - acc: 0.9772 - val_loss: 0.3297 - val_acc: 0.8646\n",
      "Epoch 49/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0711 - acc: 0.9868 - val_loss: 0.5229 - val_acc: 0.8646\n",
      "Epoch 50/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0671 - acc: 0.9928 - val_loss: 0.7034 - val_acc: 0.7604\n",
      "Epoch 51/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0773 - acc: 0.9832 - val_loss: 0.2798 - val_acc: 0.9062\n",
      "Epoch 52/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0555 - acc: 0.9880 - val_loss: 0.2479 - val_acc: 0.9375\n",
      "Epoch 53/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0819 - acc: 0.9856 - val_loss: 0.5434 - val_acc: 0.8229\n",
      "Epoch 54/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0570 - acc: 0.9892 - val_loss: 0.5604 - val_acc: 0.8542\n",
      "Epoch 55/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0528 - acc: 0.9928 - val_loss: 0.4565 - val_acc: 0.8229\n",
      "Epoch 56/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0695 - acc: 0.9844 - val_loss: 0.4733 - val_acc: 0.8229\n",
      "Epoch 57/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0740 - acc: 0.9856 - val_loss: 0.5355 - val_acc: 0.8646\n",
      "Epoch 58/100\n",
      "26/25 [===============================] - 2s 69ms/step - loss: 0.0700 - acc: 0.9844 - val_loss: 0.3494 - val_acc: 0.8646\n",
      "Epoch 59/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0493 - acc: 0.9916 - val_loss: 0.4359 - val_acc: 0.8750\n",
      "Epoch 60/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0599 - acc: 0.9856 - val_loss: 0.4205 - val_acc: 0.8854\n",
      "Epoch 61/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0479 - acc: 0.9916 - val_loss: 0.2603 - val_acc: 0.9375\n",
      "Epoch 62/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.1512 - acc: 0.9579 - val_loss: 0.3965 - val_acc: 0.8958\n",
      "Epoch 63/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.0931 - acc: 0.9784 - val_loss: 0.6898 - val_acc: 0.8333\n",
      "Epoch 64/100\n",
      "26/25 [===============================] - 2s 67ms/step - loss: 0.1269 - acc: 0.9615 - val_loss: 0.3246 - val_acc: 0.8958\n",
      "Epoch 65/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0836 - acc: 0.9844 - val_loss: 0.7368 - val_acc: 0.8229\n",
      "Epoch 66/100\n",
      "26/25 [===============================] - 2s 70ms/step - loss: 0.0480 - acc: 0.9916 - val_loss: 0.3754 - val_acc: 0.9167\n",
      "Epoch 67/100\n",
      "26/25 [===============================] - 2s 70ms/step - loss: 0.0573 - acc: 0.9844 - val_loss: 0.5119 - val_acc: 0.8646\n",
      "Epoch 68/100\n",
      "26/25 [===============================] - 2s 73ms/step - loss: 0.0479 - acc: 0.9868 - val_loss: 0.4058 - val_acc: 0.8438\n",
      "Epoch 69/100\n",
      "26/25 [===============================] - 2s 71ms/step - loss: 0.0421 - acc: 0.9952 - val_loss: 0.4163 - val_acc: 0.8229\n",
      "Epoch 70/100\n",
      "26/25 [===============================] - 2s 71ms/step - loss: 0.0356 - acc: 0.9892 - val_loss: 0.4331 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0394 - acc: 0.9928 - val_loss: 0.4445 - val_acc: 0.8229\n",
      "Epoch 72/100\n",
      "26/25 [===============================] - 2s 68ms/step - loss: 0.0411 - acc: 0.9916 - val_loss: 0.6581 - val_acc: 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1da57b438>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopping_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20)\n",
    "filename = 'HAL-9000.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_loss', save_best_only=True, mode='min')\n",
    "model.fit(train, validation_data=val, callbacks=[stopping_early, checkpoint], validation_steps = X_val.shape[0] / batch_size, steps_per_epoch=X_train.shape[0] / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/2 [================================] - 2s 709ms/step - loss: 0.7133 - acc: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7546016393082865, 0.8229167]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test, steps=X_val.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAL_9000 = tf.keras.models.load_model(\"/Users/zetong/HAL-9000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
