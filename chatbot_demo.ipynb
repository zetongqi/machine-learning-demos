{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAL-9000 intent classification demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from pymagnitude import *\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load intents dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "with open(\"/Users/zetong/intents.csv\", mode = 'r', encoding = 'ascii', errors = 'ignore') as csvfile:\n",
    "    intents = pd.read_csv(csvfile)\n",
    "    X = list(intents[\"utterances\"])\n",
    "    y = list(intents[\"labels\"])\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)\n",
    "X = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Magnitude(\"/Users/zetong/Downloads/glove.840B.300d.magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0909 18:44:29.469933 4521047488 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:44:29.480068 4521047488 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:44:29.480978 4521047488 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0909 18:44:29.481735 4521047488 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 300)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 28, 64)            85248     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                726       \n",
      "=================================================================\n",
      "Total params: 88,054\n",
      "Trainable params: 88,054\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQ_LEN = 28\n",
    "i = tf.keras.layers.Input(shape=(MAX_SEQ_LEN, vectors.dim))\n",
    "Bidir_LSTM = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, activation=\"tanh\", return_sequences=True),merge_mode=\"concat\",)(i)\n",
    "maxpool = tf.keras.layers.GlobalMaxPooling1D()(Bidir_LSTM)\n",
    "hidden = tf.keras.layers.Dense(32)(maxpool)\n",
    "dropout = tf.keras.layers.Dropout(0.3)(hidden)\n",
    "output = tf.keras.layers.Dense(le.classes_.shape[0], activation=\"softmax\")(dropout)\n",
    "model = tf.keras.Model(inputs=i, outputs=output)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(xarr, yarr):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((xarr, yarr)).repeat()\n",
    "    \n",
    "    def _process_string(x):\n",
    "\n",
    "        # x is numpy array\n",
    "        def _pad_zeros(x, MAX_SEQ_LEN):\n",
    "            if x.shape[0] >= MAX_SEQ_LEN:\n",
    "                return x[0:MAX_SEQ_LEN, :]\n",
    "            else:\n",
    "                return np.concatenate(\n",
    "                    (x, np.zeros((MAX_SEQ_LEN - x.shape[0], x.shape[1]))), axis=0\n",
    "                )\n",
    "        stemmer = LancasterStemmer()\n",
    "        x = x.numpy().decode()\n",
    "        x = word_tokenize(x)\n",
    "        x = [stemmer.stem(i) for i in x]\n",
    "        if len(x) != 0:\n",
    "            x = vectors.query(x)\n",
    "            x = _pad_zeros(x, MAX_SEQ_LEN)\n",
    "        else:\n",
    "            x = np.zeros((MAX_SEQ_LEN, vectors.dim))\n",
    "        return x\n",
    "    \n",
    "    def _process_datapair(X, y):\n",
    "        X = tf.py_function(_process_string, [X], tf.float32)\n",
    "        X.set_shape([MAX_SEQ_LEN, vectors.dim])\n",
    "        y.set_shape([])\n",
    "        return X, y\n",
    "    \n",
    "    dataset = dataset.map(_process_datapair)\n",
    "    return dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train = make_dataset(X_train, y_train)\n",
    "val = make_dataset(X_val, y_val)\n",
    "test = make_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 18:44:33.970619 4521047488 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 18:44:36.098089 123145500016640 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:44:36.119205 123145500016640 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:44:36.137377 123145500016640 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:44:36.145350 123145499480064 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n",
      "W0909 18:44:36.156615 123145500016640 backprop.py:820] The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/25 [==============================] - 9s 330ms/step - loss: 2.9688 - acc: 0.1767 - val_loss: 2.8598 - val_acc: 0.2188\n",
      "Epoch 2/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 2.7138 - acc: 0.1839 - val_loss: 2.4398 - val_acc: 0.3125\n",
      "Epoch 3/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 2.5604 - acc: 0.2308 - val_loss: 2.4701 - val_acc: 0.2708\n",
      "Epoch 4/100\n",
      "26/25 [==============================] - 2s 69ms/step - loss: 2.2605 - acc: 0.3257 - val_loss: 2.1573 - val_acc: 0.3854\n",
      "Epoch 5/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 1.8579 - acc: 0.4700 - val_loss: 1.5546 - val_acc: 0.6146\n",
      "Epoch 6/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 1.6080 - acc: 0.5000 - val_loss: 1.2450 - val_acc: 0.6667\n",
      "Epoch 7/100\n",
      "26/25 [==============================] - 2s 65ms/step - loss: 1.4219 - acc: 0.5901 - val_loss: 1.3738 - val_acc: 0.6875\n",
      "Epoch 8/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 1.2883 - acc: 0.6502 - val_loss: 1.0147 - val_acc: 0.7708\n",
      "Epoch 9/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 1.0786 - acc: 0.6971 - val_loss: 0.9123 - val_acc: 0.7812\n",
      "Epoch 10/100\n",
      "26/25 [==============================] - 2s 79ms/step - loss: 0.9835 - acc: 0.7380 - val_loss: 0.8039 - val_acc: 0.8021\n",
      "Epoch 11/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 0.9075 - acc: 0.7524 - val_loss: 0.9098 - val_acc: 0.7188\n",
      "Epoch 12/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.8062 - acc: 0.7885 - val_loss: 0.7179 - val_acc: 0.8542\n",
      "Epoch 13/100\n",
      "26/25 [==============================] - 2s 68ms/step - loss: 0.7531 - acc: 0.8173 - val_loss: 0.6388 - val_acc: 0.8958\n",
      "Epoch 14/100\n",
      "26/25 [==============================] - 2s 75ms/step - loss: 0.6968 - acc: 0.8197 - val_loss: 0.5122 - val_acc: 0.8854\n",
      "Epoch 15/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 0.5719 - acc: 0.8474 - val_loss: 0.7330 - val_acc: 0.8125\n",
      "Epoch 16/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.5747 - acc: 0.8474 - val_loss: 0.6502 - val_acc: 0.8438\n",
      "Epoch 17/100\n",
      "26/25 [==============================] - 2s 69ms/step - loss: 0.5421 - acc: 0.8558 - val_loss: 0.7285 - val_acc: 0.8646\n",
      "Epoch 18/100\n",
      "26/25 [==============================] - 2s 79ms/step - loss: 0.4716 - acc: 0.8774 - val_loss: 0.4631 - val_acc: 0.8854\n",
      "Epoch 19/100\n",
      "26/25 [==============================] - 2s 86ms/step - loss: 0.4819 - acc: 0.8678 - val_loss: 0.5571 - val_acc: 0.8646\n",
      "Epoch 20/100\n",
      "26/25 [==============================] - 3s 99ms/step - loss: 0.4195 - acc: 0.8990 - val_loss: 0.4588 - val_acc: 0.8750\n",
      "Epoch 21/100\n",
      "26/25 [==============================] - 2s 73ms/step - loss: 0.3680 - acc: 0.9038 - val_loss: 0.5831 - val_acc: 0.8542\n",
      "Epoch 22/100\n",
      "26/25 [==============================] - 2s 79ms/step - loss: 0.3807 - acc: 0.8954 - val_loss: 0.5840 - val_acc: 0.8333\n",
      "Epoch 23/100\n",
      "26/25 [==============================] - 2s 73ms/step - loss: 0.3641 - acc: 0.9075 - val_loss: 0.5990 - val_acc: 0.8438\n",
      "Epoch 24/100\n",
      "26/25 [==============================] - 2s 71ms/step - loss: 0.3246 - acc: 0.9171 - val_loss: 0.6388 - val_acc: 0.8750\n",
      "Epoch 25/100\n",
      "26/25 [==============================] - 2s 90ms/step - loss: 0.2771 - acc: 0.9423 - val_loss: 0.7117 - val_acc: 0.8229\n",
      "Epoch 26/100\n",
      "26/25 [==============================] - 2s 92ms/step - loss: 0.2570 - acc: 0.9423 - val_loss: 0.5086 - val_acc: 0.8438\n",
      "Epoch 27/100\n",
      "26/25 [==============================] - 2s 88ms/step - loss: 0.3000 - acc: 0.9375 - val_loss: 0.5359 - val_acc: 0.8646\n",
      "Epoch 28/100\n",
      "26/25 [==============================] - 2s 72ms/step - loss: 0.2510 - acc: 0.9327 - val_loss: 0.5338 - val_acc: 0.8646\n",
      "Epoch 29/100\n",
      "26/25 [==============================] - 2s 76ms/step - loss: 0.2124 - acc: 0.9471 - val_loss: 0.4407 - val_acc: 0.8542\n",
      "Epoch 30/100\n",
      "26/25 [==============================] - 2s 75ms/step - loss: 0.2115 - acc: 0.9519 - val_loss: 0.3168 - val_acc: 0.9062\n",
      "Epoch 31/100\n",
      "26/25 [==============================] - 2s 64ms/step - loss: 0.2190 - acc: 0.9399 - val_loss: 0.3371 - val_acc: 0.9167\n",
      "Epoch 32/100\n",
      "26/25 [==============================] - 2s 77ms/step - loss: 0.1937 - acc: 0.9471 - val_loss: 0.4403 - val_acc: 0.8750\n",
      "Epoch 33/100\n",
      "26/25 [==============================] - 3s 99ms/step - loss: 0.2477 - acc: 0.9339 - val_loss: 0.6399 - val_acc: 0.8646\n",
      "Epoch 34/100\n",
      "26/25 [==============================] - 2s 72ms/step - loss: 0.2035 - acc: 0.9423 - val_loss: 0.2461 - val_acc: 0.9375\n",
      "Epoch 35/100\n",
      "26/25 [==============================] - 2s 72ms/step - loss: 0.2838 - acc: 0.9375 - val_loss: 0.8436 - val_acc: 0.8021\n",
      "Epoch 36/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.1962 - acc: 0.9591 - val_loss: 0.4326 - val_acc: 0.8854\n",
      "Epoch 37/100\n",
      "26/25 [==============================] - 2s 68ms/step - loss: 0.1894 - acc: 0.9471 - val_loss: 0.4835 - val_acc: 0.8646\n",
      "Epoch 38/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 0.1519 - acc: 0.9651 - val_loss: 0.4401 - val_acc: 0.9167\n",
      "Epoch 39/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.1413 - acc: 0.9603 - val_loss: 0.4418 - val_acc: 0.9167\n",
      "Epoch 40/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 0.1129 - acc: 0.9808 - val_loss: 0.4434 - val_acc: 0.8333\n",
      "Epoch 41/100\n",
      "26/25 [==============================] - 2s 67ms/step - loss: 0.1117 - acc: 0.9748 - val_loss: 0.4975 - val_acc: 0.8229\n",
      "Epoch 42/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.1303 - acc: 0.9700 - val_loss: 0.3761 - val_acc: 0.8958\n",
      "Epoch 43/100\n",
      "26/25 [==============================] - 2s 66ms/step - loss: 0.1160 - acc: 0.9724 - val_loss: 0.5570 - val_acc: 0.8750\n",
      "Epoch 44/100\n",
      "26/25 [==============================] - 2s 73ms/step - loss: 0.1127 - acc: 0.9736 - val_loss: 0.3682 - val_acc: 0.9271\n",
      "Epoch 45/100\n",
      "26/25 [==============================] - 2s 69ms/step - loss: 0.1081 - acc: 0.9856 - val_loss: 0.5023 - val_acc: 0.8438\n",
      "Epoch 46/100\n",
      "26/25 [==============================] - 2s 71ms/step - loss: 0.1064 - acc: 0.9772 - val_loss: 0.5058 - val_acc: 0.8438\n",
      "Epoch 47/100\n",
      "26/25 [==============================] - 2s 74ms/step - loss: 0.0901 - acc: 0.9844 - val_loss: 0.3120 - val_acc: 0.8854\n",
      "Epoch 48/100\n",
      "26/25 [==============================] - 2s 68ms/step - loss: 0.0759 - acc: 0.9916 - val_loss: 0.3355 - val_acc: 0.9479\n",
      "Epoch 49/100\n",
      "26/25 [==============================] - 2s 68ms/step - loss: 0.0728 - acc: 0.9940 - val_loss: 0.4606 - val_acc: 0.8542\n",
      "Epoch 50/100\n",
      "26/25 [==============================] - 2s 71ms/step - loss: 0.0704 - acc: 0.9868 - val_loss: 0.2988 - val_acc: 0.9271\n",
      "Epoch 51/100\n",
      "26/25 [==============================] - 2s 69ms/step - loss: 0.0734 - acc: 0.9820 - val_loss: 0.4665 - val_acc: 0.9375\n",
      "Epoch 52/100\n",
      "26/25 [==============================] - 2s 75ms/step - loss: 0.1156 - acc: 0.9772 - val_loss: 0.2892 - val_acc: 0.8958\n",
      "Epoch 53/100\n",
      "26/25 [==============================] - 2s 70ms/step - loss: 0.0752 - acc: 0.9868 - val_loss: 0.4840 - val_acc: 0.8958\n",
      "Epoch 54/100\n",
      "26/25 [==============================] - 2s 71ms/step - loss: 0.0629 - acc: 0.9880 - val_loss: 0.3703 - val_acc: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d6b75c88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopping_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20)\n",
    "filename = 'HAL-9000.h5'\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filename, monitor='val_loss', save_best_only=True, mode='min')\n",
    "model.fit(train, validation_data=val, callbacks=[stopping_early, checkpoint], validation_steps = X_val.shape[0] / batch_size, steps_per_epoch=X_train.shape[0] / batch_size, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/7 [=================================] - 2s 270ms/step - loss: 0.3210 - acc: 0.9141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35688852738703924, 0.9140625]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test, steps=X_test.shape[0] / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAL_9000 = tf.keras.models.load_model(\"/Users/zetong/HAL-9000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
